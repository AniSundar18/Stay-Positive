<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Stay-Positive: A Case for Ignoring Real Image Features in Fake Image Detection">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Stay-Positive: A Case for Ignoring Real Image Features in Fake Image Detections</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>

</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
       <div class="column has-text-centered">
          <h1 class="title is-2 publication-title" style="margin-bottom: 0.25em;">
            Stay-Positive: A Case for Ignoring Real Image Features in Fake Image Detection
          </h1>
        
          <!-- Highlight acceptance info -->
          <p class="tag is-info is-light is-medium" style="margin-bottom: 1em;">
            ICML 2025
          </p>
        
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://anisundar18.github.io">Anirudh Sundara Rajan</a>,
            </span>
            <span class="author-block">
              <a href="https://pages.cs.wisc.edu/~yongjaelee/?locale=zh-cn">Yong Jae Lee</a>,
            </span>
          </div>
        
          <div class="is-size-5 publication-authors">
            <span class="author-block">University of Wisconsin-Madison</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2502.07778"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/AniSundar18/LDMFakeDetect"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Detecting AI generated images is a challenging yet essential task. A primary difficulty arises from the detectors tendency to rely on spurious patterns, such as compression artifacts, which can influence its decisions. 
            These issues often stem from specific patterns that the detector associates with the real data distribution, making it difficult to isolate the actual generative traces. 
            We argue that an image should be classified as fake if and only if it contains artifacts introduced by the generative model. Based on this premise, we propose Stay Positive, an algorithm designed to constrain the detectors focus to generative artifacts while disregarding those associated with real data. 
            Experimental results demonstrate that detectors trained with Stay Positive exhibit reduced susceptibility to spurious correlations, leading to improved generalization and robustness to post processing. 
            Additionally, unlike detectors that associate artifacts with real images, those that focus purely on fake artifacts are better at detecting inpainted real images.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Key Insight</h2>

    <!-- Diagram/Image at the top -->
    <div class="mb-5">
      <figure class="image">
        <img src="static/images/insight.png" alt="Key Insight Diagram" />
      </figure>
    </div>

    <!-- Textual Explanation -->
    <div class="content has-text-justified">
      <p>
        <strong>Consider this toy example.</strong> We have three images: a real one on the left, an LDM-generated one in the middle, and a FLUX-generated one on the right. During training, we're only exposed to the first two — real and LDM-generated. So it seems reasonable to assume that <em>real images tend to have clean, readable text</em>, and the generated ones don’t.
      </p>

      <p>
        But at test time, we introduce FLUX, which is <em>also a latent diffusion model</em>, just a more advanced one. And now, the generated images start to look a lot more like the real ones, especially in how they render text.
      </p>

      <p>
        That earlier assumption — that <em>good text means the image is real</em> — breaks down. What we found is that relying on such assumptions can actually hurt the detector’s performance. It can get confused, even when there are still <em>other clear signs that the image was generated</em>.
      </p>
    </div>
  </div>
</div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">A Simple Fix</h2>
    
        <!-- Assumptions Section -->
        <div class="content has-text-justified mb-5">
        <p>
          To address the issue, we make three key assumptions:
        </p>
        <ul>
          <li><strong>Assumption 1:</strong> Class 0 denotes the real distribution, and Class 1 denotes the distribution of AI-generated images.</li>
          <li><strong>Assumption 2:</strong> The score output by the network passes through the sigmoid activation before the decision.</li>
          <li><strong>Assumption 3:</strong> The feature vector extracted by the neural network before applying the linear classification layer is passed through the ReLU activation.</li>
        </ul>
  
        <p>
          These three assumptions can be easily satisfied by popular modern networks, including ResNet-50. These networks are commonly used for binary classification tasks and already incorporate such mechanisms in their design.
        </p>
      </div>
    
        <!-- Diagram/Image -->
        <div class="mb-5">
          <figure class="image">
            <img src="static/images/teaser.png" alt="Our Algorithm Diagram" />
          </figure>
        </div>
    
        <!-- Algorithm Explanation -->
        <div class="content has-text-justified">
          <p>
              The first assumption we make is about the class labels: class 0 for real images and class 1 for fake images. This is a typical setup for binary classification. Next, we use a monotonically-increasing sigmoid activation function (Assumption-2), which means the detector will give higher scores to AI-generated images compared to real ones. 
          </p>
          
          <p>
              In addition, according to Assumption-3, the input to the linear classifier is a vector with strictly non-negative values. Each dimension of this vector represents a specific feature or pattern that influences the decision the neural network makes.
          </p>
          
          <p>
              The network assigns a weight to each feature. If the weight is positive, the presence of that feature will increase the score, making it more likely that the image will be classified as fake. Conversely, if the weight is negative, the image is more likely to be classified as real.
          </p>
          
          <p>
              The key insight here is that finding certain features should never increase the likelihood of an image being real. To address this, we retrain only the final classification layer, keeping the rest of the network frozen. We ensure that the weights "stay-positive" to stop patterns associated with real images from influencing the decision.
          </p>
        </div>
      </div>
    </div>

    
    <!-- Paper video. -->
<!--     <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  <!--</div> -->
  
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

  <!-- Improved Generalization -->
  <div class="column">
    <div class="content">
      <h2 class="title is-3">Improved Generalization to other Generators</h2>
      <div class="mb-5">
        <figure class="image">
          <img src="static/images/genral.png" alt="Generalization Diagram" />
        </figure>
      </div>
      <p>
        We observe that existing detectors underperform on images coming from different generators since they rely on spurious real features (Section 3.2).
        The plot shows that strong detectors (Rajan, Corvi) struggle to detect images generated by FLUX and aMUSEd. However, after applying the Stay-Positive algorithm,
        they are able to detect these images.
      </p>
    </div>
  </div>
  <!-- /Improved Generalization -->

  <!-- Detecting Partial Inpainting -->
  <div class="column">
    <div class="content">
      <h2 class="title is-3 has-text-centered">Detecting Partially-Inpainted Images</h2>
      <div class="mb-5 has-text-centered">
        <figure class="image is-inline-block">
          <img src="static/images/inp.png" alt="Inpainting Detection Diagram" />
        </figure>
      </div>
      <p>
        The figure shows an image of a painting (human-created), which has been partially modified by Stable Diffusion in various regions.
        Existing detectors often struggle with images where only a small region has been generated, while the rest remains real.
        This is understandable—since most of the image is authentic, it can dominate the detector’s decision.
        In contrast, our method remains effective even in these challenging cases, successfully identifying such partially generated images.
      </p>
    </div>
  </div>
  <!-- /Detecting Partial Inpainting -->

</div>


    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Limitations and Future Work</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4"></h3>
        <div class="content has-text-justified">
          <p>
            The original detector can still learn spurious features indicative of fake images. In Appendix A.4, we provide an example showing that the absence of a specific feature commonly found in real images can be exploited to identify fake ones.
The Stay-Positive algorithm does not fully address this issue. Therefore, future work should aim to mitigate such problems during the initial stage of training.
          </p>
        </div>
        
        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{rajan2025staypositivecaseignoringreal,
      title={Stay-Positive: A Case for Ignoring Real Image Features in Fake Image Detection}, 
      author={Anirudh Sundara Rajan and Yong Jae Lee},
      year={2025},
      eprint={2502.07778},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2502.07778}, 
}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
